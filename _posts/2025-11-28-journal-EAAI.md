---
layout: post
title:  Engineering Applications of Artificial Intelligence (EAAI) (Q1 Journal) 
date:   2025-11-28 00:00:00 +0900
image:  2025/EAAI.jpg
tags:   News
published: true
description: Our paper, "Enhancing multimodal emotion recognition with dynamic fuzzy membership and attention fusion", has been accepted by the "Engineering Applications of Artificial Intelligence" Journal.
---

- About [Engineering Applications of Artificial Intelligence (EAAI)](https://www.sciencedirect.com/journal/engineering-applications-of-artificial-intelligence)

- [Nhut Minh Nguyen](https://aita-lab.github.io/member/nmnhut), [Minh Trung Nguyen](https://aita-lab.github.io/member/nmtrung), [Thanh Trung Nguyen](https://aita-lab.github.io/member/nttrung), [Phuong-Nam Tran](https://tpnam0901.github.io), [Nhat Truong Pham](https://nhattruongpham.github.io/), [Linh Le](https://mila.quebec/en/directory/linh-le), [Alice Othmani](http://www.lissi.fr/personnel/alice-ahlem-othmani/), [Abdulmotaleb El Saddik](https://mcrlab.net/team/elsaddik/) and [Duc Ngoc Minh Dang](https://aita-lab.github.io/member/dnmduc), "Enhancing multimodal emotion recognition with dynamic fuzzy membership and attention fusion": This paper introduces FleSER, a new multimodal emotion recognition architecture that combines dynamic fuzzy membership with attention-based fusion. Unlike most existing SER models that apply fuzzy logic only at the decision level, FleSER uses a feature-level rule-based fuzzy mechanism to refine audio and text representations before fusion. Our design also incorporates self- and cross-modality attention, along with an Î±-interpolation fusion strategy, allowing the model to adaptively emphasize whichever modality (audio or text) is more informative in each context. FleSER achieves state-of-the-art performance across multiple benchmark datasets, with extensive ablation studies confirming the effectiveness of each architectural component. This work is a step forward in building more robust, adaptive, and accurate emotion recognition systems.